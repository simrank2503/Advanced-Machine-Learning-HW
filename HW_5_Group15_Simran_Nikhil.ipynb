{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0gfAbD1BRax"
   },
   "source": [
    "# Assignment 5 #\n",
    "### Due: Friday, November 17th to be submitted via Canvas by 11:59 pm ###\n",
    "### Total points: **65** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWSTziq5jJ4P"
   },
   "source": [
    "Homework Group - 15\n",
    "<br> <br>\n",
    "Student Names - <br>Simran Kaur (sk57859), <br>Nikhil Nair (nn8446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omOSpxMmBTQE"
   },
   "source": [
    "# Q1: Support Vector Machines (10 points)\n",
    "\n",
    "In this question, we will explore support vector machines for the Spam Base dataset from the UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0GbdHYxjLiok"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tVj75ETFMaUJ"
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26ixmQ9qT6z3",
    "outputId": "06a75107-6c0d-4a08-8065-3aac49bb6bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\simran\\anaconda3\\lib\\site-packages (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlQyfxg0YuB0",
    "outputId": "691ff4c8-0b49-4305-d1e6-7afee70bb04e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: Classifying Email as Spam or Non-Spam\n",
      "Number of instances: 4601\n",
      "Number of features: 57\n",
      "0                 word_freq_make\n",
      "1              word_freq_address\n",
      "2                  word_freq_all\n",
      "3                   word_freq_3d\n",
      "4                  word_freq_our\n",
      "5                 word_freq_over\n",
      "6               word_freq_remove\n",
      "7             word_freq_internet\n",
      "8                word_freq_order\n",
      "9                 word_freq_mail\n",
      "10             word_freq_receive\n",
      "11                word_freq_will\n",
      "12              word_freq_people\n",
      "13              word_freq_report\n",
      "14           word_freq_addresses\n",
      "15                word_freq_free\n",
      "16            word_freq_business\n",
      "17               word_freq_email\n",
      "18                 word_freq_you\n",
      "19              word_freq_credit\n",
      "20                word_freq_your\n",
      "21                word_freq_font\n",
      "22                 word_freq_000\n",
      "23               word_freq_money\n",
      "24                  word_freq_hp\n",
      "25                 word_freq_hpl\n",
      "26              word_freq_george\n",
      "27                 word_freq_650\n",
      "28                 word_freq_lab\n",
      "29                word_freq_labs\n",
      "30              word_freq_telnet\n",
      "31                 word_freq_857\n",
      "32                word_freq_data\n",
      "33                 word_freq_415\n",
      "34                  word_freq_85\n",
      "35          word_freq_technology\n",
      "36                word_freq_1999\n",
      "37               word_freq_parts\n",
      "38                  word_freq_pm\n",
      "39              word_freq_direct\n",
      "40                  word_freq_cs\n",
      "41             word_freq_meeting\n",
      "42            word_freq_original\n",
      "43             word_freq_project\n",
      "44                  word_freq_re\n",
      "45                 word_freq_edu\n",
      "46               word_freq_table\n",
      "47          word_freq_conference\n",
      "48                   char_freq_;\n",
      "49                   char_freq_(\n",
      "50                   char_freq_[\n",
      "51                   char_freq_!\n",
      "52                   char_freq_$\n",
      "53                   char_freq_#\n",
      "54    capital_run_length_average\n",
      "55    capital_run_length_longest\n",
      "56      capital_run_length_total\n",
      "57                         Class\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "# fetch dataset\n",
    "spambase = fetch_ucirepo(id=94)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = spambase.data.features\n",
    "y = spambase.data.targets\n",
    "print(\"Abstract:\", spambase.metadata['abstract'])\n",
    "print(\"Number of instances:\", spambase.metadata['num_instances'])\n",
    "print(\"Number of features:\", spambase.metadata['num_features'])\n",
    "print(spambase.variables['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Hkpnd9HBjUMm"
   },
   "outputs": [],
   "source": [
    "# Reloading based on update mail\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"spambase.data\", header=None)\n",
    "y = df[57]\n",
    "X = df.drop(columns=[57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "lmKGx3T8ZXci",
    "outputId": "d89ede24-c309-480c-ffbc-6a78152be840"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...   47    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.0  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.0  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.0  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tukYZVbDZsG-"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "y = y.to_numpy().squeeze()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jdODxjI41xm"
   },
   "source": [
    "a. (5 points) Implement the following function to train SVMs with a specified kernel type, hyper-parameter search space, and random state on the Spam Base dataset. Do hyper-parameter search over $C$ using [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), setting the number of folds to 5. After finding the best C, please use it to train the final model and return both the final model and the best C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K90sxpVK7mED"
   },
   "outputs": [],
   "source": [
    "def search_best_svm(kernel, C_search_space, random_state):\n",
    "    best_score = -np.inf\n",
    "    for C in C_search_space:\n",
    "        # Initialize an SVM classifier with the specified kernel type, C value, and random state\n",
    "        ### START CODE ###\n",
    "        svm_classifier = SVC(kernel=kernel, C=C, random_state=random_state)\n",
    "        ### END CODE ###\n",
    "\n",
    "        # Evaluate accuracy scores using 5-fold cross-validation scores\n",
    "        ### START CODE ###\n",
    "        scores = cross_val_score(svm_classifier, X_train, y_train, cv=5)\n",
    "        ### END CODE ###\n",
    "\n",
    "        # Compute the average score and compare with the current best score to update the best C\n",
    "        ### START CODE ###\n",
    "        score = np.mean(scores)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "        ### END CODE ###\n",
    "        print(f\"C: {C:.3f}{'':<5}Avg Cross Val Score: {np.round(score, 3)}\")\n",
    "\n",
    "    print(f\"Best C: {best_C}\")\n",
    "\n",
    "    # Initialize the model using the specified kernel type, best C, and random state;\n",
    "    # and then fit the model using training set\n",
    "    ### START CODE ###\n",
    "    model = SVC(kernel=kernel, C=best_C, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    ### END CODE ###\n",
    "    return model, best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ_MU9Fl6EIn"
   },
   "source": [
    "b. (3 points) Run the function you implemented above to train SVMs with the search space of $C$ being [$0.1, 1, 10, 100$], random state set to 42, with the following three popular kernels: (i) linear (ii) polynomial (iii) RBF (Gaussian). Evaluate your final models on the test set and report their accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qucC2PdjJ4V",
    "outputId": "06cd941e-4782-43b1-bd29-a31445025785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training linear SVM:\n",
      "C: 0.100     Avg Cross Val Score: 0.921\n",
      "C: 1.000     Avg Cross Val Score: 0.926\n",
      "C: 10.000     Avg Cross Val Score: 0.928\n",
      "C: 100.000     Avg Cross Val Score: 0.927\n",
      "Best C: 10\n",
      "\n",
      "Training poly SVM:\n",
      "C: 0.100     Avg Cross Val Score: 0.689\n",
      "C: 1.000     Avg Cross Val Score: 0.759\n",
      "C: 10.000     Avg Cross Val Score: 0.843\n",
      "C: 100.000     Avg Cross Val Score: 0.896\n",
      "Best C: 100\n",
      "\n",
      "Training rbf SVM:\n",
      "C: 0.100     Avg Cross Val Score: 0.896\n",
      "C: 1.000     Avg Cross Val Score: 0.924\n",
      "C: 10.000     Avg Cross Val Score: 0.924\n",
      "C: 100.000     Avg Cross Val Score: 0.912\n",
      "Best C: 10\n",
      "\n",
      "\n",
      "Test accuracy with linear kernel and best C=10: 0.928\n",
      "Test accuracy with poly kernel and best C=100: 0.913\n",
      "Test accuracy with rbf kernel and best C=10: 0.935\n"
     ]
    }
   ],
   "source": [
    "# C search space\n",
    "C_search_space = [0.1, 1, 10, 100]\n",
    "\n",
    "# Kernel types\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "\n",
    "# Initialize dictionaries to store the models and best C values\n",
    "svm_models = {}\n",
    "best_C_values = {}\n",
    "\n",
    "# Train SVMs with different kernels and find the best C for each\n",
    "for kernel in kernels:\n",
    "    print(f\"\\nTraining {kernel} SVM:\")\n",
    "    model, best_C = search_best_svm(kernel, C_search_space, seed)\n",
    "    svm_models[kernel] = model\n",
    "    best_C_values[kernel] = best_C\n",
    "\n",
    "# Evaluate and report accuracies of the final models on the test set\n",
    "print(f\"\\n\")\n",
    "for kernel in kernels:\n",
    "    model = svm_models[kernel]\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"Test accuracy with {kernel} kernel and best C={best_C_values[kernel]}: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCxwqenL6nZ4"
   },
   "source": [
    "c. (2 points) Train a logistic regression model using the training set. Compare its performance with that of the SVMs trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Pt0ojbbkjJ4W",
    "outputId": "e16a84e0-4bd3-41c2-d591-319015dee8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Logistic Regression: 0.9223\n",
      "\n",
      "Test accuracy for linear SVM: 0.9283 (Best C: 10)\n",
      "SVM with linear kernel outperforms Logistic Regression\n",
      "\n",
      "Test accuracy for poly SVM: 0.9125 (Best C: 100)\n",
      "Logistic Regression outperforms SVM with poly kernel\n",
      "\n",
      "Test accuracy for rbf SVM: 0.9354 (Best C: 10)\n",
      "SVM with rbf kernel outperforms Logistic Regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "logreg = LogisticRegression(random_state=seed, max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "logreg_test_accuracy = accuracy_score(y_test, logreg.predict(X_test))\n",
    "print(f\"Test accuracy for Logistic Regression: {logreg_test_accuracy:.4f}\\n\")\n",
    "\n",
    "# Compare with SVM models\n",
    "for kernel in kernels:\n",
    "    svm_test_accuracy = accuracy_score(y_test, svm_models[kernel].predict(X_test))\n",
    "    print(f\"Test accuracy for {kernel} SVM: {svm_test_accuracy:.4f} (Best C: {best_C_values[kernel]})\")\n",
    "\n",
    "    # Compare the results\n",
    "    if svm_test_accuracy > logreg_test_accuracy:\n",
    "        print(f\"SVM with {kernel} kernel outperforms Logistic Regression\\n\")\n",
    "    elif svm_test_accuracy < logreg_test_accuracy:\n",
    "        print(f\"Logistic Regression outperforms SVM with {kernel} kernel\\n\")\n",
    "    else:\n",
    "        print(f\"SVM with {kernel} kernel and Logistic Regression have the same accuracy\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVgBWtheoudc"
   },
   "source": [
    "> **Support Vector Machines (SVMs) potentially exhibit superior performance over Logistic Regression in various scenarios.** This can be attributed to SVMs' capacity to manage non-linear data correlations by incorporating non-linear kernels. Their resilience to outliers also plays a crucial role, enabling SVMs to better generalize across intricate datasets, unlike the linear decision boundary defined by Logistic Regression. The enhancement in performance is further bolstered by the opportunities for fine-tuning SVM parameters and employing the kernel trick, which offers a versatile approach to discerning complex patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc9ca1b5"
   },
   "source": [
    "# Question 2 : Ensemble Methods for Classification (25 pts)\n",
    "\n",
    "In this question, we will compare the performances of different ensemble methods for classification problems: [Bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html), [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [XGBoost](https://xgboost.readthedocs.io/en/stable/python/python_api.html) classifiers.\n",
    "\n",
    "We will look at the [GiveMeSomeCredit](https://www.kaggle.com/c/GiveMeSomeCredit) dataset for this question. The dataset is extremely large so for this question we will only consider a subset which has been provided along with the notebook for this assignment. The dataset has already been split into train and test sets.\n",
    "\n",
    "The task is to predict the probability that someone will experience financial distress in the next two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a93b913f"
   },
   "outputs": [],
   "source": [
    "# Only use this code block if you are using Google Colab.\n",
    "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
    "from google.colab import files\n",
    "\n",
    "## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file.\n",
    "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1a2bac93",
    "outputId": "5961e9b7-e4c0-4613-e447-10d7821d2402"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.571373</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430620</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233999</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257380</td>\n",
       "      <td>5656.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.299270</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114575</td>\n",
       "      <td>4747.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308326</td>\n",
       "      <td>8490.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.050591</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862627</td>\n",
       "      <td>3333.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "0                 0                              0.571373   66   \n",
       "1                 0                              0.233999   56   \n",
       "2                 0                              0.299270   33   \n",
       "3                 0                              0.032165   41   \n",
       "4                 0                              0.050591   36   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                     0   0.430620         9274.0   \n",
       "1                                     0   0.257380         5656.0   \n",
       "2                                     0   0.114575         4747.0   \n",
       "3                                     0   0.308326         8490.0   \n",
       "4                                     0   0.862627         3333.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                               10                        0   \n",
       "1                               12                        0   \n",
       "2                                8                        0   \n",
       "3                                8                        0   \n",
       "4                                8                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                             1                                     0   \n",
       "1                             0                                     0   \n",
       "2                             0                                     0   \n",
       "3                             1                                     0   \n",
       "4                             2                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 3.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('hw5_data.csv')\n",
    "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fb34060d",
    "outputId": "12b5d678-a0b3-424c-9c2e-cda67e03e236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (3750, 10) (3750,)\n",
      "test: (1250, 10) (1250,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data['SeriousDlqin2yrs']\n",
    "X = data.drop(['SeriousDlqin2yrs'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 7)\n",
    "\n",
    "print('train:',X_train.shape, y_train.shape)\n",
    "print('test:',X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "90d16082"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score)\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "import xgboost\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "420aeb16"
   },
   "outputs": [],
   "source": [
    "columns_list = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f40f9107"
   },
   "source": [
    "a. (2.5 pts) Fit a Decision Tree Classifier with random_state = 14 for this classification problem. Report the accuracy_score and roc_auc_score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "45de59e6"
   },
   "outputs": [],
   "source": [
    "def fit_classifier(clf):\n",
    "    # Fit the classifier on the training set\n",
    "    ### START CODE ###\n",
    "    clf.fit(X_train, y_train)\n",
    "    ### END CODE ###\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yZfiYRKtHJQ4"
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(clf, X_test, y_test):\n",
    "  # Compute the accuracy_score, and roc_auc_score on the test set\n",
    "  ### START CODE ###\n",
    "  y_pred = clf.predict(X_test)\n",
    "  y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "  acc_score = accuracy_score(y_test, y_pred)\n",
    "  auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "  ### END CODE ###\n",
    "  print(\"Accuracy_score: {}, ROC_AUC_score: {}\".format(acc_score, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9a436542",
    "outputId": "58468273-95a0-4587-e133-1bf15dccb017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy_score: 0.888, ROC_AUC_score: 0.5854582176218127\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree\")\n",
    "# Initialize your decision tree classifier\n",
    "### START CODE ###\n",
    "dt_clf = DecisionTreeClassifier(random_state=14)\n",
    "### END CODE ###\n",
    "\n",
    "dt_clf = fit_classifier(dt_clf)\n",
    "evaluate_classifier(dt_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d360a99"
   },
   "source": [
    "b. (2.5 pts) Create a [Bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) of 25 classifiers (i.e, n_estimators=25) with random_state=14. Please use Decision Tree Classifier with random_state=14 as the base classifier. Report accuracy_score and roc_auc_score on the test data for this emsemble classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "239c9c3c",
    "outputId": "4e4cd33d-10ed-4cc8-b006-464c3a52965e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging of Decesion Trees\n",
      "Accuracy_score: 0.9256, ROC_AUC_score: 0.7857106791214341\n"
     ]
    }
   ],
   "source": [
    "print(\"Bagging of Decesion Trees\")\n",
    "# Initialize your bagging classifier\n",
    "### START CODE ###\n",
    "bag_clf = BaggingClassifier(base_estimator=dt_clf, n_estimators=25, random_state=14)\n",
    "### END CODE ###\n",
    "\n",
    "bag_clf = fit_classifier(bag_clf)\n",
    "evaluate_classifier(bag_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34225ee3"
   },
   "source": [
    "c. (5 pts) In this question, you will fit a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model on the training data for this classification task.\n",
    "\n",
    "1. First, please find the best parameters (including *n_estimators*, *max_features* and *criterion*) using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Report the optimal parameters obtained by GridSearch.\n",
    "2. Fit a model using the best parameters, and report the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and [roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "R9E7sMGt2goM"
   },
   "outputs": [],
   "source": [
    "def grid_search_for_classifier(clf, param_grid, X_train, y_train):\n",
    "  # Grid search\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "\n",
    "  # Conduct grid search using the training set (1 line of code only)\n",
    "  ### START CODE ###\n",
    "    grid_search.fit(X_train, y_train)\n",
    "  ### END CODE ###\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "  # Set the best paramters for your clf (1 line of code only)\n",
    "  ### START CODE ###\n",
    "    clf.set_params(**grid_search.best_params_)\n",
    "  ### END CODE ###\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4UyA2_rB2gG9"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    t0 = time()\n",
    "  # Fit your classifier on the training set\n",
    "  ### START CODE ###\n",
    "    clf.fit(X_train, y_train)\n",
    "  ### END CODE ###\n",
    "    print(\"training time\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "    t0 = time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"predict time\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "    print(\"Confusion matrix: \")\n",
    "  # Print the confusion matrix computed from the test set (1 line of code only)\n",
    "  ### START CODE ###\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "  ### END CODE ###\n",
    "\n",
    "\n",
    "  ### START CODE ###\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "  ### END CODE ###\n",
    "\n",
    "    print(\"Accuracy: {}, AUC_ROC: {}\".format(acc_score, auc_score))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6bfb9542",
    "outputId": "2b94e5d7-d6ea-4705-b5d4-e6b960c2ebfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 1, 'n_estimators': 100, 'random_state': 17}\n",
      "training time 0.432 s\n",
      "predict time 0.016 s\n",
      "Confusion matrix: \n",
      "[[1162    3]\n",
      " [  82    3]]\n",
      "Accuracy: 0.932, AUC_ROC: 0.8375612219136582\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=1, random_state=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=1, random_state=17)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=1, random_state=17)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [1, 10, 50, 100],\n",
    "              \"max_features\": [1, 5, 10, \"auto\"],\n",
    "              \"criterion\": ['gini','entropy'],\n",
    "              \"random_state\": [17]}\n",
    "\n",
    "# Initialize your random forest classifier\n",
    "### START CODE ###\n",
    "rf_clf = RandomForestClassifier()\n",
    "### END CODE ###\n",
    "rf_clf = grid_search_for_classifier(rf_clf, param_grid, X_train, y_train)\n",
    "train_and_evaluate_classifier(rf_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "314c313b"
   },
   "source": [
    "d. (10 pts) This time, let us use [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) and [XGBoost](https://xgboost.readthedocs.io/en/stable/python/python_api.html) for the same task. For AdaBoost and XGBoost, please respectively find the best parameters (including *n_estimators, learning_rate*); fit your model using the best parameters, and report the confusion matrix and roc_auc_score on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3222ef25"
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [10, 100],\n",
    "          \"learning_rate\": [0.01, 0.1, 0.5],\n",
    "          \"random_state\": [17]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bp4Ekjpy1cGw",
    "outputId": "3cc89d08-01cd-496b-f6b3-10b5854eaa04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 100, 'random_state': 17}\n",
      "training time 0.442 s\n",
      "predict time 0.016 s\n",
      "Confusion matrix: \n",
      "[[1153   12]\n",
      " [  72   13]]\n",
      "Accuracy: 0.9328, AUC_ROC: 0.8390254986114618\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=17)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize your AdaBoost classifier\n",
    "### START CODE ###\n",
    "ab_clf = AdaBoostClassifier()\n",
    "### END CODE ###\n",
    "ab_clf = grid_search_for_classifier(ab_clf, param_grid, X_train, y_train)\n",
    "train_and_evaluate_classifier(ab_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Hv0p1mZh2CqA",
    "outputId": "b28ae150-fe25-471a-8ebe-4ed012f3232d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'n_estimators': 100, 'random_state': 17}\n",
      "training time 0.094 s\n",
      "predict time 0.0 s\n",
      "Confusion matrix: \n",
      "[[1163    2]\n",
      " [  84    1]]\n",
      "Accuracy: 0.9312, AUC_ROC: 0.8267962635698057\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=17, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=17, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=17, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize your XGBoost classifier\n",
    "### START CODE ###\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier()\n",
    "### END CODE ###\n",
    "xgb_clf = grid_search_for_classifier(xgb_clf, param_grid, X_train, y_train)\n",
    "train_and_evaluate_classifier(xgb_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6bc87cd"
   },
   "source": [
    "f. (5 pts) Compare the performance of decision tree from part a) with the ensemble methods. Briefly explain which of the three ensemble methods performed better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg_qEaYyjJ4a"
   },
   "source": [
    "| Method         | Accuracy Score | ROC AUC Score            |\n",
    "| -------------- | -------------- | ------------------------ |\n",
    "| Decision Tree  | 0.888          | 0.5854582176218127       |\n",
    "| Bagging  | 0.9256|0.7857106791214341   |\n",
    "| Random Forest  | 0.932       | 0.8375612219136582       |\n",
    "| Adaboost | 0.9328      |  0.8390254986114618   |\n",
    "|XGBoost | 0.9312 | 0.8267962635698057 |\n",
    "\n",
    ">We can clearly see that the Ensemble methods performed better than the Decision Trees, as they have consistently outperformed the Decision Tree in both accuracy and ROC AUC score.\n",
    "<br><br>\n",
    "Amongst the ensemble methods, Adaboost is performing the best here, with the highest accuracy and ROC, wheras Random Forest is the close second. The choice between AdaBoost and Random Forest might depend on the specific requirements of the task, the interpretability of the model, and considerations regarding computational efficiency.\n",
    "<br><br>\n",
    "In conclusion, we can say that when compared to the Decision Tree, all the ensemble methods demonstrate improved performance, with AdaBoost being the top performer in this particular evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZXTR1tM7yBp"
   },
   "source": [
    "# Q3: CatBoost (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zcExque_yso"
   },
   "source": [
    "In this question you will learn about a boosting algorithm known as **CatBoost**. Please go through the two videos specified below to get a better understanding of the CatBoost algorithm and answer the questions that follow.\n",
    "\n",
    "[Part-1](https://www.youtube.com/watch?v=KXOTSkPL2X4&ab_channel=StatQuestwithJoshStarmer)\n",
    "[Part - 2](https://www.youtube.com/watch?v=3Bg2XRFOTzg&t=242s&ab_channel=StatQuestwithJoshStarmer)\n",
    "\n",
    "\n",
    "\n",
    "a. **(5 points)** Briefly explain Ordered Target Encoding. What challenge does it try to address?\n",
    "\n",
    "b. **(5 points)** Briefly describe the main advantages and disadvantages of CatBoost as compared to XGBoost."
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "id": "93cq1BKSjJ4f"
   },
   "source": [
    "> a)\n",
    "<br>\n",
    "Ordered Target Encoding in CatBoost is a specialized technique for encoding categorical variables whihch acknowledges the sequential arrangement of rows in a dataset. This approach revolves around the concept of treating each data row as if it were fed into the algorithm sequentially, ensuring that the encoding process respects the chronological order of the data, processing each row in the order it appears and taking into account the information available up to that point. Instead of relying on an overarching mean, CatBoost introduces the use of a predefined prior or guess for encoding, a value often determined through domain knowledge or experimental insights. Furthermore, the encoding equation is streamlined for computational efficiency by simplifying it through the addition of 1 to the denominator.\n",
    "<br> The equation for calculatinf Catboost encoding is given by the formula :\n",
    "![image-2.png](attachment:image-2.png)\n",
    "The method itself is inherently sequential, leveraging information from all preceding rows when encoding the current row. Notably, the order of data is paramount in this encoding process, culminating in the designation of \"Ordered Target Encoding.\" Overall, this technique is a deliberate and effective strategy within CatBoost, ensuring that encoding decisions are made with a keen awareness of the historical context of the data.\n",
    "<br> <br>\n",
    "The challenge that Ordered Target Encoding in CatBoost addresses is the prevention of data leakage during the encoding process. By treating each row sequentially and incorporating information only from preceding rows, the method ensures that the encoding is based on historical data, preventing future information from influencing the encoding of the current row. This is particularly relevant when dealing with time-series or sequentially ordered data in machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aod23t-gjJ4f"
   },
   "source": [
    ">b)\n",
    "<br>CatBoost has distinct characteristics that set it apart from other Gradient Boosting methods, particularly in comparison to XGBoost.\n",
    "<br><br>**Advantages of CatBoost:**\n",
    "<br><br>\n",
    "-- CatBoost handles categorical variables efficiently without the need for explicit preprocessing, whereas XGBoost requires preprocessing of categorical variables, which can involve one-hot encoding or label encoding.\n",
    "<br><br>\n",
    "-- The Ordered Target Encoding approach prevents data leakage by treating data as if it arrives sequentially, which proves advantageous for time-series or sequentially ordered datasets, whereas XGBoost is prone to data leakage\n",
    "<br><br>\n",
    "-- Catboost uses symmetric decision trees, while intentionally weakening individual trees to obtain a consistent structure which facilitate faster predictions,  which increases the overall effectiveness of the ensemble. Whereas, XGBoost builds asymmetric trees and may require more computations during tree building, potentially impacting speed\n",
    "<br><br><br>\n",
    "**Disadvantages of CatBoost:**\n",
    "<br><br>\n",
    "-- The use of symmetric decision trees intentionally makes individual trees weaker. While this aligns with the ensemble learning philosophy, it may result in each tree being less powerful compared to those in other boosting methods like XGBoost.\n",
    "<br><br>\n",
    "-- The effectiveness of CatBoost is sensitive to the choice of hyperparameters, such as the learning rate. Fine-tuning these parameters might be crucial for achieving optimal performance, whereas XGBoost is generally robust to hyperparameter choices, and default parameters often yield good results.\n",
    "<br><br>\n",
    "-- While CatBoost is known for its out-of-the-box performance, its documentation might be considered less extensive than that of XGBoost. This could pose challenges for users who require detailed guidance or troubleshooting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTFRT23o76A2"
   },
   "source": [
    "# Q4: Convolutional Neural Network (20 points)\n",
    "In this question, we will continue our exercise on the SVHN classification task from the previous homework, but this time we will be using Convolutional Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lW0odgzmXUU_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Dr0KdJ2LrCCV"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oBCdEj-_0tkS",
    "outputId": "cf9f7fcf-642d-4229-dd85-9580276b9d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\train_32x32.mat\n",
      "Using downloaded and verified file: .\\test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614))\n",
    "        ])\n",
    "\n",
    "train_dataset = torchvision.datasets.SVHN(root='.', split='train', transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.SVHN(root='.', split='test', transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iLn4YKK90vjo"
   },
   "outputs": [],
   "source": [
    "train_num = int(len(train_dataset) * 0.8)\n",
    "val_num = len(train_dataset) - train_num\n",
    "# Randomly split the training dataset into training dataset and validation dataset\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_num, val_num])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFUXsbsqjoCw"
   },
   "source": [
    "a. (10 points) Build a convolutional neural network with the following sequential configuration. If not specified, please use the default setting of torch.nn.Conv2d. The output of the convolution layers will be fed into a fully-connected MLP. Then train the model with Adam optimizer (lr=1e-3) for 10 epochs. You should be able to achieve test accuracy of over 85%.\n",
    "\n",
    "\n",
    "\n",
    "> Layer 1\n",
    "*   2d convolution (# input channel=3, # output channel=16, kernel size=3, padding=1)\n",
    "*   2d batch normalization\n",
    "*   Relu activation\n",
    "\n",
    "> Pool 1\n",
    "*   2d max pooling (kernel size=2)\n",
    "\n",
    "> Layer 2\n",
    "*   2d convolution (# output channel=16, kernel size=3, padding=1)\n",
    "*   2d batch normalization\n",
    "*   Relu activation\n",
    "\n",
    "> Pool 2\n",
    "*   2d max pooling (kernel size=2)\n",
    "\n",
    "> Layer 3\n",
    "*   2d convolution (# output channel=32, kernel size=3, padding=1)\n",
    "*   2d batch normalization\n",
    "*   Relu activation\n",
    "\n",
    "> Pool 3\n",
    "*   2d max pooling (kernel size=2)\n",
    "\n",
    "References:\n",
    "\n",
    "*   https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "*   https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
    "*   https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "*   https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "M8OcO88V01Rr"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, pool=True):\n",
    "        super(CNN, self).__init__()\n",
    "        self.pool = pool\n",
    "\n",
    "        # Create convolutional layers\n",
    "        ### START CODE ###\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        ### END CODE ###\n",
    "\n",
    "        # Create fully connected layers (nn.Linear)\n",
    "        if self.pool:\n",
    "            self.mlp1 = nn.Linear(32*4*4, 50)\n",
    "        else:\n",
    "            self.mlp1 = nn.Linear(32*32*32, 50)\n",
    "\n",
    "        self.mlp2 = nn.Linear(50, 50)\n",
    "        self.mlp3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        if self.pool:\n",
    "            x = self.pool1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        if self.pool:\n",
    "            x = self.pool2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        if self.pool:\n",
    "            x = self.pool3(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = F.relu(self.mlp1(x))\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        x = self.mlp3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ygrxekov097w"
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_num = 0\n",
    "    for data, target in tqdm(loader):\n",
    "        out = model(data)\n",
    "        # Calculate loss based on model output and target\n",
    "        loss = F.nll_loss(F.log_softmax(out, dim=1), target)\n",
    "\n",
    "        # Use the optimizer to perform backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = len(target)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_num += batch_size\n",
    "    avg_loss = total_loss / total_num\n",
    "    return avg_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_num = 0\n",
    "    for data, target in tqdm(loader):\n",
    "        out = model(data)\n",
    "        # Calculate loss based on model output and target\n",
    "        loss = F.nll_loss(F.log_softmax(out, dim=1), target)\n",
    "\n",
    "        # Get model's prediction\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "\n",
    "        # Count number of correct predictions\n",
    "        correct = accuracy_score(target, pred, normalize=False)\n",
    "\n",
    "        total_correct += correct\n",
    "        batch_size = len(target)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_num += batch_size\n",
    "    avg_loss = total_loss / total_num\n",
    "    acc = total_correct / total_num\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "aET_5IqXDsC1",
    "outputId": "8a2e7fcc-8c17-4018-e589-0d67cfaba79f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:26<00:00,  8.54it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 1.227153619493542 Val Loss: 0.6528453861726558 Val Acc: 0.8035763035763036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:32<00:00,  6.95it/s]\n",
      "100%|██████████| 58/58 [00:04<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.5629423191417007 Val Loss: 0.49593723576120297 Val Acc: 0.8568796068796068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:33<00:00,  6.82it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.4619430889805453 Val Loss: 0.46834037067897977 Val Acc: 0.8613158613158614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:36<00:00,  6.24it/s]\n",
      "100%|██████████| 58/58 [00:04<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss: 0.4140270362366345 Val Loss: 0.4317820750028424 Val Acc: 0.8744881244881245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:29<00:00,  7.65it/s]\n",
      "100%|██████████| 58/58 [00:05<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.3774644328789971 Val Loss: 0.4150832778332567 Val Acc: 0.8789243789243789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:32<00:00,  7.10it/s]\n",
      "100%|██████████| 58/58 [00:05<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Train Loss: 0.3526003925354954 Val Loss: 0.40542702623771376 Val Acc: 0.8775593775593775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:31<00:00,  7.25it/s]\n",
      "100%|██████████| 58/58 [00:04<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Train Loss: 0.3361472487429305 Val Loss: 0.38950670426119033 Val Acc: 0.8846573846573846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:27<00:00,  8.21it/s]\n",
      "100%|██████████| 58/58 [00:04<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train Loss: 0.31951572166684444 Val Loss: 0.3798684354789134 Val Acc: 0.8882063882063882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:27<00:00,  8.24it/s]\n",
      "100%|██████████| 58/58 [00:04<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Train Loss: 0.3018927976871735 Val Loss: 0.3821809963836001 Val Acc: 0.8877968877968878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:28<00:00,  8.00it/s]\n",
      "100%|██████████| 58/58 [00:04<00:00, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.2915703554271828 Val Loss: 0.3665769079849104 Val Acc: 0.8943488943488943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = CNN(pool=True)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\n",
    "best_acc = -np.inf\n",
    "epochs = 10\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = train(model1, train_loader, optimizer)\n",
    "    val_loss, val_acc = eval(model1, val_loader)\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model1 = model1\n",
    "    print(f\"Epoch: {e} Train Loss: {train_loss} Val Loss: {val_loss} Val Acc: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "A7Za_DdlDwJX",
    "outputId": "400569cf-4342-478e-c830-78c931ce76a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:09<00:00, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = eval(best_model1, test_loader)\n",
    "print(f\"Test accuracy: {np.round(test_acc, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLAnNsjsnRpK"
   },
   "source": [
    "b. (5 points) Use torch-summary to print a summary of the model. The number of parameters should be less than the one of the MLP we trained in the previous homework. Why does it have less number of parameters but have higher accuracy?\n",
    "\n",
    "Reference\n",
    "*   https://pypi.org/project/torch-summary/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "tkuRsoNxR8dX",
    "outputId": "de567666-5856-40a6-dd98-53a0f1af366f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary in c:\\users\\simran\\anaconda3\\lib\\site-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "fAw8KglVjJ4k",
    "outputId": "503c4708-2668-4c9b-aa4b-7d0a7270b9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 16, 32, 32]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 16, 32, 32]          448\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 16, 32, 32]          32\n",
      "|    └─ReLU: 2-3                         [-1, 16, 32, 32]          --\n",
      "├─MaxPool2d: 1-2                         [-1, 16, 16, 16]          --\n",
      "├─Sequential: 1-3                        [-1, 16, 16, 16]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 16, 16, 16]          2,320\n",
      "|    └─BatchNorm2d: 2-5                  [-1, 16, 16, 16]          32\n",
      "|    └─ReLU: 2-6                         [-1, 16, 16, 16]          --\n",
      "├─MaxPool2d: 1-4                         [-1, 16, 8, 8]            --\n",
      "├─Sequential: 1-5                        [-1, 32, 8, 8]            --\n",
      "|    └─Conv2d: 2-7                       [-1, 32, 8, 8]            4,640\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 32, 8, 8]            64\n",
      "|    └─ReLU: 2-9                         [-1, 32, 8, 8]            --\n",
      "├─MaxPool2d: 1-6                         [-1, 32, 4, 4]            --\n",
      "├─Linear: 1-7                            [-1, 50]                  25,650\n",
      "├─Linear: 1-8                            [-1, 50]                  2,550\n",
      "├─Linear: 1-9                            [-1, 10]                  510\n",
      "==========================================================================================\n",
      "Total params: 36,246\n",
      "Trainable params: 36,246\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.36\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.34\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 0.49\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 16, 32, 32]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 16, 32, 32]          448\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 16, 32, 32]          32\n",
       "|    └─ReLU: 2-3                         [-1, 16, 32, 32]          --\n",
       "├─MaxPool2d: 1-2                         [-1, 16, 16, 16]          --\n",
       "├─Sequential: 1-3                        [-1, 16, 16, 16]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 16, 16, 16]          2,320\n",
       "|    └─BatchNorm2d: 2-5                  [-1, 16, 16, 16]          32\n",
       "|    └─ReLU: 2-6                         [-1, 16, 16, 16]          --\n",
       "├─MaxPool2d: 1-4                         [-1, 16, 8, 8]            --\n",
       "├─Sequential: 1-5                        [-1, 32, 8, 8]            --\n",
       "|    └─Conv2d: 2-7                       [-1, 32, 8, 8]            4,640\n",
       "|    └─BatchNorm2d: 2-8                  [-1, 32, 8, 8]            64\n",
       "|    └─ReLU: 2-9                         [-1, 32, 8, 8]            --\n",
       "├─MaxPool2d: 1-6                         [-1, 32, 4, 4]            --\n",
       "├─Linear: 1-7                            [-1, 50]                  25,650\n",
       "├─Linear: 1-8                            [-1, 50]                  2,550\n",
       "├─Linear: 1-9                            [-1, 10]                  510\n",
       "==========================================================================================\n",
       "Total params: 36,246\n",
       "Trainable params: 36,246\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.36\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.34\n",
       "Params size (MB): 0.14\n",
       "Estimated Total Size (MB): 0.49\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model1, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_haa3ZEpicr"
   },
   "source": [
    "> CNNs surpass MLPs in image processing due to their efficient architecture. Their convolutional layers are adept at handling spatial relationships and reduce redundancy with parameter sharing and local connectivity, focusing on important features. Unlike MLPs, CNNs keep the spatial structure of images intact, capturing critical patterns like edges through a process that scans the entire image. Pooling layers further contribute to a CNN's capability to be resilient to slight shifts in position. Overall, these features enable CNNs to be more accurate and efficient than MLPs for tasks involving spatial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eb6rNHsobVb"
   },
   "source": [
    "c. (5 points) Train another CNN with the pool option set to False. What are the differences in terms of accuracy or computation caused by disabling max pooling? What are the effects of pooling operations in CNNs? (This might take some time. Watch a TV show while you're waiting for the results..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1m-9yG9VAbgE",
    "outputId": "a047dfdd-e171-42d5-e755-d915b9f7a8e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:55<00:00,  4.10it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 1.0626374755237464 Val Loss: 0.5920150863922524 Val Acc: 0.8273273273273273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [01:09<00:00,  3.30it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.5050778144262886 Val Loss: 0.4975972994409426 Val Acc: 0.8542178542178542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:59<00:00,  3.84it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.4170285483786153 Val Loss: 0.4586346668279988 Val Acc: 0.8652061152061152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [01:02<00:00,  3.68it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss: 0.3588758644939903 Val Loss: 0.427585068326357 Val Acc: 0.875034125034125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [01:04<00:00,  3.55it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.3199208781167658 Val Loss: 0.4320681552287499 Val Acc: 0.8748293748293748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:59<00:00,  3.82it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Train Loss: 0.2804446710019518 Val Loss: 0.4252813093215756 Val Acc: 0.8776276276276276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [01:02<00:00,  3.66it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Train Loss: 0.24893411738037932 Val Loss: 0.43172284613337764 Val Acc: 0.8782418782418783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [01:00<00:00,  3.78it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train Loss: 0.21813443109002825 Val Loss: 0.45254963003414234 Val Acc: 0.8746246246246246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [01:02<00:00,  3.65it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Train Loss: 0.1929111884288867 Val Loss: 0.4593426128562083 Val Acc: 0.8746246246246246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [01:00<00:00,  3.77it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17332333062642183 Val Loss: 0.4715987218230141 Val Acc: 0.874010374010374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = CNN(pool=False)\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
    "best_acc = -np.inf\n",
    "epochs = 10\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = train(model2, train_loader, optimizer)\n",
    "    val_loss, val_acc = eval(model2, val_loader)\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model2 = model2\n",
    "    print(f\"Epoch: {e} Train Loss: {train_loss} Val Loss: {val_loss} Val Acc: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "13gIhnYVAbgQ",
    "outputId": "96c93ce1-e3d4-472d-ca97-1ba71f860a74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:11<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491087891825445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = eval(best_model2, test_loader)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fvqtCpsppMS"
   },
   "source": [
    "> Disabling pooling in CNNs leads to greater model complexity and significantly longer training times without a substantial increase in accuracy. After 10 epochs, model1 **with pooling** achieves an accuracy of 0.887, while model2 **without pooling** has a slightly lower accuracy of 0.849 but incurs much higher computational costs. The higher resolution in model2 doesn't translate into better performance in this dataset, as the reduction in spatial dimensions by max pooling in model1 doesn't detrimentally affect accuracy but does improve efficiency drastically. Thus, while omitting max pooling could be beneficial for tasks necessitating detailed spatial information, in this scenario, enabling max pooling is the more time-efficient choice with a negligible impact on accuracy."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bc9ca1b5",
    "jZXTR1tM7yBp"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
